# ì¶”ì²œ ì‹œìŠ¤í…œ (llm-worker-rec)

ì‚¬ìš©ìì˜ ë¸Œë¼ìš°ì§• íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ê°œì¸í™”ëœ ì½˜í…ì¸  ì¶”ì²œì„ ì œê³µí•˜ëŠ” gRPC ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

## ì£¼ìš” ê¸°ëŠ¥

### ê°œì¸í™” ì¶”ì²œ
- **ë¸Œë¼ìš°ì§• íŒ¨í„´ ë¶„ì„**: ì‚¬ìš©ìì˜ ì›¹ ì„œí•‘ í–‰ë™ ë¶„ì„
- **ì½˜í…ì¸  ìœ í˜• ë¶„ë¥˜**: ê´€ì‹¬ì‚¬ë³„ ì½˜í…ì¸  ì¹´í…Œê³ ë¦¬í™”
- **ì‹¤ì‹œê°„ ì¶”ì²œ**: ì‚¬ìš©ì í–‰ë™ ë³€í™”ì— ë”°ë¥¸ ë™ì  ì¶”ì²œ

### AI ê¸°ë°˜
- **OpenAI GPT**: ê³ í’ˆì§ˆ ì¶”ì²œ ì½˜í…ì¸  ìƒì„±
- **Perplexity API**: ë³´ì¡° AI ì„œë¹„ìŠ¤ í™œìš©
- **ë§¥ë½ ì´í•´**: ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ë§ì¶¤í˜• ì¶”ì²œ

### gRPC
- **ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ**: ì‹¤ì‹œê°„ ì¶”ì²œ ê²°ê³¼ ì „ë‹¬
- **íƒ€ì… ì•ˆì „ì„±**: Protocol Buffers ê¸°ë°˜
- **ê³ ì„±ëŠ¥**: HTTP/2 ê¸°ë°˜ í†µì‹ 

## ì„œë¹„ìŠ¤ êµ¬ì¡°

### gRPC í”„ë¡œí† ì½œ ì •ì˜
```protobuf
// protos/recommendation.proto
syntax = "proto3";

package recommendation;

message RecommendRequest {
  string user_id = 1;
  string browser_context = 2;  // ë¸Œë¼ìš°ì € ìˆ˜ì§‘ ì •ë³´ (JSON)
  string content_type = 3;     // ì¶”ì²œ ì»¨í…ì¸  ìœ í˜•
  string content_period = 4;   // ì»¨í…ì¸  ê¸°ê°„ í•„í„°
}

message RecommendResponse {
  string content = 1;      // ì¶”ì²œ ê²°ê³¼ (ìŠ¤íŠ¸ë¦¼ chunk)
  string is_final = 2;     // ë§ˆì§€ë§‰ chunk ì—¬ë¶€
}

service RecommendationService {
  rpc Recommend (RecommendRequest) returns (stream RecommendResponse);
}
```

### ì£¼ìš” í•¨ìˆ˜ë“¤

#### 1. ë¸Œë¼ìš°ì§• ë°ì´í„° ë¶„ì„
```python
def analyze_browsing_pattern(browser_context: dict) -> dict:
    """ë¸Œë¼ìš°ì§• íŒ¨í„´ ë¶„ì„"""
    analysis = {
        "topics": extract_topics(browser_context),
        "interests": analyze_interests(browser_context),
        "behavior_pattern": analyze_behavior(browser_context),
        "content_preferences": extract_preferences(browser_context)
    }
    return analysis
```

#### 2. ê´€ì‹¬ì‚¬ ì¶”ì¶œ
```python
def extract_topics(browser_context: dict) -> List[str]:
    """ë°©ë¬¸í•œ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ê´€ì‹¬ì‚¬ ì¶”ì¶œ"""
    topics = []
    
    for site in browser_context.get("visited_sites", []):
        url = site.get("url", "")
        title = site.get("title", "")
        
        # URLê³¼ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = extract_keywords(url, title)
        topics.extend(keywords)
    
    # ì¤‘ë³µ ì œê±° ë° ë¹ˆë„ ë¶„ì„
    return get_top_topics(topics, limit=10)
```

#### 3. AI ì¶”ì²œ ìƒì„±
```python
async def generate_recommendations(user_id: str, analysis: dict, content_type: str = "general") -> str:
    """AIë¥¼ ì‚¬ìš©í•œ ê°œì¸í™” ì¶”ì²œ ìƒì„±"""
    prompt = f"""
    ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ë¸Œë¼ìš°ì§• íŒ¨í„´ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:
    
    ì‚¬ìš©ì ID: {user_id}
    ê´€ì‹¬ì‚¬: {analysis['topics']}
    í–‰ë™ íŒ¨í„´: {analysis['behavior_pattern']}
    ì½˜í…ì¸  ì„ í˜¸ë„: {analysis['content_preferences']}
    ìš”ì²­ ìœ í˜•: {content_type}
    
    ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ì½˜í…ì¸ ë¥¼ ì¶”ì²œí•´ ì£¼ì„¸ìš”.
    ì¶”ì²œì€ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì´ì–´ì•¼ í•˜ë©°, ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    
    response = await call_openai_api(prompt)
    return response
```

#### 4. OpenAI API í˜¸ì¶œ
```python
async def call_openai_api(prompt: str) -> str:
    """OpenAI API í˜¸ì¶œ"""
    import openai
    
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬ì™€ í–‰ë™ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ê°œì¸í™”ëœ ì½˜í…ì¸ ë¥¼ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        stream=True,
        max_tokens=500,
        temperature=0.7
    )
    
    return response
```

## ë°ì´í„° íë¦„

### 1. ì¶”ì²œ ìƒì„± íŒŒì´í”„ë¼ì¸
```
ë¸Œë¼ìš°ì§• ë°ì´í„° â†’ íŒ¨í„´ ë¶„ì„ â†’ AI ì¶”ì²œ ìƒì„± â†’ ì‹¤ì‹œê°„ ì „ì†¡
```

### 2. ì‚¬ìš©ì í–‰ë™ ë¶„ì„
```
ë°©ë¬¸ ì‚¬ì´íŠ¸ â†’ ê´€ì‹¬ì‚¬ ì¶”ì¶œ â†’ ì„ í˜¸ë„ ë¶„ì„ â†’ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜
```

### 3. ì‹¤ì‹œê°„ í†µì‹ 
```
FastAPI â†’ gRPC ìŠ¤íŠ¸ë¦¬ë° â†’ OpenAI API â†’ WebSocket â†’ í´ë¼ì´ì–¸íŠ¸
```

## í™˜ê²½ ì„¤ì •

### í™˜ê²½ ë³€ìˆ˜
```bash
# AI ì„œë¹„ìŠ¤ API í‚¤
OPENAI_API_KEY=your_openai_api_key
PERPLEXITY_API_KEY=your_perplexity_api_key

# gRPC ì„œë²„ ì„¤ì •
GRPC_PORT=50051
```

### ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

### ì„œë¹„ìŠ¤ ì‹¤í–‰
```bash
# Docker Composeë¡œ ì‹¤í–‰
docker-compose up llm-worker-rec

# ë˜ëŠ” ì§ì ‘ ì‹¤í–‰
python main.py
```

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
llm-worker-rec/
â”œâ”€â”€ main.py                 # gRPC ì„œë²„ ë©”ì¸ íŒŒì¼
â”œâ”€â”€ requirements.txt        # Python ì˜ì¡´ì„±
â”œâ”€â”€ Dockerfile             # Docker ì´ë¯¸ì§€ ì •ì˜
â”œâ”€â”€ protos/                # Protocol Buffers ì •ì˜
â”‚   â””â”€â”€ recommendation.proto
â””â”€â”€ README.md              # ì´ íŒŒì¼
```

## ğŸ”„ gRPC ì„œë¹„ìŠ¤ êµ¬í˜„

### ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
```python
class RecommendationService(recommendation_pb2_grpc.RecommendationServiceServicer):
    async def Recommend(self, request, context):
        """ì¶”ì²œ gRPC ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤"""
        try:
            # 1. ìš”ì²­ ë°ì´í„° íŒŒì‹±
            browser_context = json.loads(request.browser_context)
            user_id = request.user_id
            content_type = request.content_type
            content_period = request.content_period
            
            # 2. ë¸Œë¼ìš°ì§• íŒ¨í„´ ë¶„ì„
            analysis = analyze_browsing_pattern(browser_context)
            
            # 3. AI ì¶”ì²œ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë°
            async for chunk in generate_recommendations(user_id, analysis, content_type):
                yield recommendation_pb2.RecommendResponse(
                    content=chunk,
                    is_final="false"
                )
            
            # 4. ìµœì¢… ì‘ë‹µ
            yield recommendation_pb2.RecommendResponse(
                content="ì¶”ì²œ ì™„ë£Œ",
                is_final="true"
            )
            
        except Exception as e:
            context.abort(grpc.StatusCode.INTERNAL, f"ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
```

### ì„œë²„ ì‹¤í–‰
```python
async def serve():
    """gRPC ì„œë²„ ì‹¤í–‰"""
    server = grpc.aio.server()
    recommendation_pb2_grpc.add_RecommendationServiceServicer_to_server(
        RecommendationService(), server
    )
    
    listen_addr = f'[::]:{os.getenv("GRPC_PORT", "50051")}'
    server.add_insecure_port(listen_addr)
    
    await server.start()
    await server.wait_for_termination()
```

## ì„±ëŠ¥ ìµœì í™”

### 1. ìºì‹± ì „ëµ
```python
# ì‚¬ìš©ì ë¶„ì„ ê²°ê³¼ ìºì‹±
import asyncio
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_analyze_browsing_pattern(browser_context_hash: str) -> dict:
    """ë¸Œë¼ìš°ì§• íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ìºì‹±"""
    return analyze_browsing_pattern(browser_context_hash)
```

### 2. ë¹„ë™ê¸° ì²˜ë¦¬
```python
# ì—¬ëŸ¬ ë¶„ì„ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰
async def parallel_analysis(browser_context: dict) -> dict:
    """ë³‘ë ¬ ë¶„ì„ ì²˜ë¦¬"""
    tasks = [
        analyze_topics(browser_context),
        analyze_interests(browser_context),
        analyze_behavior(browser_context)
    ]
    
    results = await asyncio.gather(*tasks)
    return {
        "topics": results[0],
        "interests": results[1],
        "behavior": results[2]
    }
```

### 3. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
```python
# ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì²œ ê²°ê³¼ ì „ë‹¬
async for chunk in ai_response:
    yield RecommendResponse(content=chunk, is_final="false")
```

## ë””ë²„ê¹…

### ë¡œê·¸ í™•ì¸
```bash
# Docker ë¡œê·¸
docker-compose logs -f llm-worker-rec

# ì§ì ‘ ì‹¤í–‰ ì‹œ
python main.py --debug
```

### gRPC í…ŒìŠ¤íŠ¸
```python
# gRPC í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸
import grpc
import recommendation_pb2
import recommendation_pb2_grpc

async def test_recommendation():
    async with grpc.aio.insecure_channel('localhost:50051') as channel:
        stub = recommendation_pb2_grpc.RecommendationServiceStub(channel)
        
        browser_context = {
            "visited_sites": [
                {"url": "https://github.com", "title": "GitHub"},
                {"url": "https://stackoverflow.com", "title": "Stack Overflow"}
            ],
            "search_queries": ["python tutorial", "machine learning"],
            "time_spent": {"github.com": 1200, "stackoverflow.com": 800}
        }
        
        request = recommendation_pb2.RecommendRequest(
            user_id="test_user",
            browser_context=json.dumps(browser_context),
            content_type="technical",
            content_period="recent"
        )
        
        async for response in stub.Recommend(request):
            print(f"ì¶”ì²œ: {response.content}")
```

## ëª¨ë‹ˆí„°ë§

### ì„±ëŠ¥ ë©”íŠ¸ë¦­
- **ì²˜ë¦¬ ì‹œê°„**: ì¶”ì²œ ìƒì„± ì†Œìš” ì‹œê°„
- **ì‚¬ìš©ì ë§Œì¡±ë„**: ì¶”ì²œ í´ë¦­ë¥ 
- **ì„±ê³µë¥ **: ì¶”ì²œ ìƒì„± ì„±ê³µ ë¹„ìœ¨
- **ì—ëŸ¬ìœ¨**: API í˜¸ì¶œ ì‹¤íŒ¨ ë¹„ìœ¨

### ë¡œê·¸ ë¶„ì„
```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì²˜ë¦¬ ê³¼ì • ë¡œê¹…
logger.info(f"ì¶”ì²œ ì‹œì‘: ì‚¬ìš©ì {user_id}")
logger.info(f"ë¶„ì„ëœ ê´€ì‹¬ì‚¬: {len(topics)}ê°œ")
logger.info(f"ì¶”ì²œ ìƒì„± ì™„ë£Œ: {len(recommendation)} ë¬¸ì")
```

## ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### ê°œì¸ì •ë³´ ë³´í˜¸
- **ë°ì´í„° ìµëª…í™”**: ì‚¬ìš©ì ì‹ë³„ ì •ë³´ ì œê±°
- **ì•”í˜¸í™”**: ë¯¼ê°í•œ ë¸Œë¼ìš°ì§• ë°ì´í„° ì•”í˜¸í™”
- **ì ‘ê·¼ ì œì–´**: API í‚¤ ê¸°ë°˜ ì¸ì¦

### ì…ë ¥ ê²€ì¦
```python
def validate_browser_context(browser_context: dict) -> bool:
    """ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì¦"""
    required_fields = ["visited_sites", "search_queries"]
    
    for field in required_fields:
        if field not in browser_context:
            return False
    
    # ë°ì´í„° í¬ê¸° ì œí•œ
    if len(str(browser_context)) > 10000:
        return False
    
    return True
```

### ì—ëŸ¬ ì²˜ë¦¬
```python
try:
    # ë¸Œë¼ìš°ì§• ë°ì´í„° ë¶„ì„
    analysis = analyze_browsing_pattern(browser_context)
    if not analysis:
        raise ValueError("ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
except Exception as e:
    # ì ì ˆí•œ ì—ëŸ¬ ì‘ë‹µ
    context.abort(grpc.StatusCode.INVALID_ARGUMENT, str(e))
```
